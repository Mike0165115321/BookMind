"""
Evaluator ‚Äî Assesses information sufficiency for the Agentic RAG loop.

After each search iteration, the Evaluator checks:
  1. Does the gathered information cover all aspects of the query?
  2. What's missing? What follow-up queries could fill the gaps?
  3. Confidence score: 0.0 (nothing useful) ‚Üí 1.0 (fully sufficient)

This is the "quality gate" that decides when to STOP searching.
Without this, the agent would either search too little or loop forever.

Decision Logic:
  confidence >= threshold ‚Üí STOP, generate answer
  confidence < threshold  ‚Üí CONTINUE, search with follow-up queries
  max_iterations reached  ‚Üí STOP regardless (hard limit)
"""
import json
from dataclasses import dataclass, field
from groq import Groq
from core.config import settings
from core.key_manager import groq_key_manager


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Result Data Structure
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@dataclass
class EvaluationResult:
    """Result of sufficiency evaluation."""
    is_sufficient: bool             # True if enough info to answer well
    confidence: float               # 0.0 - 1.0 confidence score
    missing_aspects: list[str]      # What's still missing
    follow_up_queries: list[str]    # Suggested queries to fill gaps
    reasoning: str = ""             # Why this evaluation


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Evaluation Prompt
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
EVALUATE_SYSTEM_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö:
1. ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
2. Sub-queries ‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
3. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß

‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô:
- confidence 0.8-1.0 = ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ
- confidence 0.5-0.79 = ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
- confidence 0.0-0.49 = ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠

- ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ follow_up_queries (1-2 ‡∏≠‡∏±‡∏ô) ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
- follow_up_queries ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å sub_queries ‡πÄ‡∏î‡∏¥‡∏° (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡πâ‡∏ô‡∏ã‡πâ‡∏≥)

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{
  "is_sufficient": true/false,
  "confidence": 0.0-1.0,
  "missing_aspects": ["‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏Ç‡∏≤‡∏î..."],
  "follow_up_queries": ["query ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°..."],
  "reasoning": "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ"
}"""


def _get_groq_client() -> Groq:
    """Create a Groq client with the next API key from rotation."""
    api_key = groq_key_manager.get_key()
    if not api_key:
        raise RuntimeError("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ API key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Groq ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô .env")
    return Groq(api_key=api_key)


def evaluate_sufficiency(
    original_query: str,
    sub_queries: list[str],
    context_summary: str,
    threshold: float = 0.7,
) -> EvaluationResult:
    """
    Evaluate whether gathered information is sufficient to answer the query.

    Uses Groq LLM to analyze coverage of the original query
    against the information gathered so far.

    Args:
        original_query: The user's original question
        sub_queries: List of sub-queries that were planned
        context_summary: Summary of gathered chunks from AgentMemory
        threshold: Confidence threshold for sufficiency

    Returns:
        EvaluationResult with is_sufficient, confidence, and follow-up queries
    """
    try:
        client = _get_groq_client()

        user_prompt = f"""‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {original_query}

Sub-queries ‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÑ‡∏ß‡πâ: {json.dumps(sub_queries, ensure_ascii=False)}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏î‡πâ:
{context_summary}

‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""

        response = client.chat.completions.create(
            model=settings.GROQ_MODEL,
            messages=[
                {"role": "system", "content": EVALUATE_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            max_tokens=256,
            temperature=0.2,
            response_format={"type": "json_object"},
        )

        raw = response.choices[0].message.content.strip()
        parsed = json.loads(raw)

        confidence = float(parsed.get("confidence", 0.5))
        is_sufficient = confidence >= threshold
        missing = parsed.get("missing_aspects", [])
        follow_ups = parsed.get("follow_up_queries", [])
        reasoning = parsed.get("reasoning", "")

        result = EvaluationResult(
            is_sufficient=is_sufficient,
            confidence=confidence,
            missing_aspects=missing,
            follow_up_queries=follow_ups,
            reasoning=reasoning,
        )

        status = "‚úÖ ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠" if is_sufficient else "üîÑ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö"
        print(f"   üìä Evaluate: {status} (confidence={confidence:.2f}, threshold={threshold})")
        if missing:
            for m in missing:
                print(f"      ‚ùå ‡∏Ç‡∏≤‡∏î: {m}")
        if follow_ups:
            for fq in follow_ups:
                print(f"      üîç ‡∏Ñ‡πâ‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°: {fq}")

        return result

    except Exception as e:
        print(f"   ‚ö†Ô∏è  Evaluate failed ({e}), assuming sufficient")
        return EvaluationResult(
            is_sufficient=True,
            confidence=0.5,
            missing_aspects=[],
            follow_up_queries=[],
            reasoning=f"Fallback due to error: {e}",
        )
"""
"""
